# üìò Gu√≠a de Uso - Proyecto de An√°lisis de Terremotos

## üéØ Bienvenido

Esta gu√≠a te ayudar√° a ejecutar todos los componentes del proyecto de an√°lisis de terremotos. Lee cuidadosamente cada secci√≥n antes de comenzar.

---

## üìã Prerrequisitos

### Software Necesario

1. **Python 3.8 o superior**
   - Descarga desde: https://www.python.org/downloads/
   - Aseg√∫rate de marcar "Add Python to PATH" durante la instalaci√≥n

2. **R y RStudio** (para mapas)
   - R desde: https://cran.r-project.org/
   - RStudio desde: https://posit.co/download/rstudio-desktop/

3. **Editor de c√≥digo** (opcional pero recomendado)
   - VS Code: https://code.visualstudio.com/

### Dataset Requerido

**Archivo:** `Earthquakes_USGS.csv`
- Col√≥calo en: `data/raw/Earthquakes_USGS.csv`
- Si no tienes el archivo, desc√°rgalo del USGS Earthquake Catalog

---

## üöÄ Instalaci√≥n

### 1. Instalar Dependencias de Python

Abre PowerShell en la carpeta del proyecto y ejecuta:

```powershell
# Instalar todas las librer√≠as necesarias
pip install pandas numpy matplotlib seaborn scikit-learn scipy joblib
```

**Librer√≠as instaladas:**
- `pandas`: Manipulaci√≥n de datos
- `numpy`: Operaciones num√©ricas
- `matplotlib` y `seaborn`: Visualizaciones
- `scikit-learn`: Modelos de machine learning
- `scipy`: Estad√≠sticas avanzadas
- `joblib`: Guardado de modelos

### 2. Instalar Paquetes de R

Abre RStudio y ejecuta:

```r
# Instalar paquetes necesarios
install.packages(c("ggplot2", "sf", "rnaturalearth", 
                   "rnaturalearthdata", "dplyr", "readr", 
                   "viridis", "scales"))
```

---

## üìÇ Estructura del Proyecto

```
DM/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dataset original aqu√≠
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Earthquakes_USGS.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Datos limpios (generados)
‚îÇ       ‚îî‚îÄ‚îÄ earthquakes_clean.csv
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ python/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_data_cleaning.py          # Limpieza de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_descriptive_analysis.py   # An√°lisis estad√≠stico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_visualizations.py         # Gr√°ficos Python
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 04_analytical_models.py      # Modelos ML
‚îÇ   ‚îî‚îÄ‚îÄ R/
‚îÇ       ‚îú‚îÄ‚îÄ 01_load_and_clean.R          # Carga en R
‚îÇ       ‚îî‚îÄ‚îÄ 02_maps_visualization.R      # Mapas mundiales
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ earthquakes_analysis_colab.ipynb # Notebook completo
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                # Gr√°ficos generados
‚îÇ   ‚îî‚îÄ‚îÄ results/                # Reportes y modelos
‚îî‚îÄ‚îÄ README.md
```

---

## üé¨ Ejecuci√≥n Paso a Paso

### OPCI√ìN A: Ejecuci√≥n Local (Python + R)

#### Paso 1: Limpieza de Datos (Python)

```powershell
cd "C:\Users\jaime\Documents\DM"
python scripts/python/01_data_cleaning.py
```

**Qu√© hace:**
- Carga el dataset original
- Elimina duplicados y valores inv√°lidos
- Crea columnas de a√±o, d√©cada, mes
- Exporta: `data/processed/earthquakes_clean.csv`
- Genera: `outputs/results/cleaning_report.txt`

**Tiempo estimado:** 2-10 minutos (depende del tama√±o del dataset)

**Salida esperada:**
```
‚úì‚úì‚úì LIMPIEZA COMPLETADA EXITOSAMENTE ‚úì‚úì‚úì
Registros finales: XXX,XXX
```

---

#### Paso 2: An√°lisis Descriptivo (Python)

```powershell
python scripts/python/02_descriptive_analysis.py
```

**Qu√© hace:**
- Calcula estad√≠sticas descriptivas (media, mediana, desviaci√≥n)
- Analiza distribuci√≥n temporal (por a√±o, d√©cada)
- Identifica regiones m√°s afectadas
- Calcula correlaciones
- Genera: `outputs/results/descriptive_statistics.txt`

**Tiempo estimado:** 1-3 minutos

**Salida esperada:**
```
‚úì‚úì‚úì AN√ÅLISIS DESCRIPTIVO COMPLETADO EXITOSAMENTE ‚úì‚úì‚úì
```

---

#### Paso 3: Visualizaciones en Python

```powershell
python scripts/python/03_visualizations.py
```

**Qu√© hace:**
- Genera 8 visualizaciones profesionales:
  1. Histograma de magnitudes
  2. Histograma de profundidades
  3. Boxplots por d√©cada
  4. Tendencia temporal
  5. Magnitud promedio por a√±o
  6. Scatter profundidad vs magnitud
  7. Heatmap de correlaciones
  8. Top regiones afectadas

**Archivos generados:** `outputs/figures/01_*.png` a `08_*.png`

**Tiempo estimado:** 2-5 minutos

---

#### Paso 4: Mapas en R

**Opci√≥n 4A: Desde RStudio**

1. Abre RStudio
2. File ‚Üí Open File ‚Üí `scripts/R/02_maps_visualization.R`
3. Selecciona todo el c√≥digo (Ctrl+A)
4. Run (Ctrl+Enter)

**Opci√≥n 4B: Desde l√≠nea de comandos**

```powershell
Rscript scripts/R/02_maps_visualization.R
```

**Qu√© hace:**
- Genera 4 mapas mundiales de alta calidad:
  1. Distribuci√≥n global de sismos
  2. Sismos de alta magnitud (‚â•7.0)
  3. Mapa de densidad
  4. Clasificaci√≥n por profundidad

**Archivos generados:** `outputs/figures/map_01_*.png` a `map_04_*.png`

**Tiempo estimado:** 3-8 minutos

---

#### Paso 5: Modelos Anal√≠ticos (Python)

```powershell
python scripts/python/04_analytical_models.py
```

**Qu√© hace:**
- Regresi√≥n lineal simple y m√∫ltiple
- Clustering KMeans
- PCA (An√°lisis de Componentes Principales)
- M√©todo del codo para K √≥ptimo
- Guarda modelos entrenados en `outputs/results/models/`

**Tiempo estimado:** 3-10 minutos

---

### OPCI√ìN B: Google Colab (Todo en uno)

Si prefieres ejecutar todo en Google Colab:

1. **Subir el notebook:**
   - Ve a: https://colab.research.google.com/
   - File ‚Üí Upload notebook
   - Selecciona: `notebooks/earthquakes_analysis_colab.ipynb`

2. **Subir dataset:**
   - Usa el bot√≥n üìÅ en el panel izquierdo
   - Sube `Earthquakes_USGS.csv`
   - O ejecuta la celda de carga que incluye `files.upload()`

3. **Ejecutar todo:**
   - Runtime ‚Üí Run all
   - O ejecuta celda por celda (Shift+Enter)

**Ventajas de Colab:**
- No requiere instalaci√≥n local
- Gratis con GPU/TPU
- F√°cil de compartir
- Todo en un solo archivo

**Tiempo estimado total:** 15-30 minutos

---

## üìä Verificaci√≥n de Resultados

### Archivos que deben generarse:

#### En `data/processed/`:
- ‚úÖ `earthquakes_clean.csv` - Dataset limpio

#### En `outputs/figures/`:
- ‚úÖ `01_magnitude_distribution.png`
- ‚úÖ `02_depth_distribution.png`
- ‚úÖ `03_magnitude_by_decade.png`
- ‚úÖ `04_earthquakes_per_year.png`
- ‚úÖ `05_average_magnitude_per_year.png`
- ‚úÖ `06_depth_vs_magnitude.png`
- ‚úÖ `07_correlation_heatmap.png`
- ‚úÖ `08_top_regions.png`
- ‚úÖ `map_01_world_earthquakes.png`
- ‚úÖ `map_02_high_magnitude.png`
- ‚úÖ `map_03_density.png`
- ‚úÖ `map_04_depth_classification.png`
- ‚úÖ `model_01_linear_regression_simple.png`
- ‚úÖ `model_02_kmeans_clustering.png`
- ‚úÖ `model_03_pca_analysis.png`
- ‚úÖ `model_04_elbow_method.png`

#### En `outputs/results/`:
- ‚úÖ `cleaning_report.txt`
- ‚úÖ `descriptive_statistics.txt`
- ‚úÖ `model_report.txt`
- ‚úÖ `frequency_tables_decades.csv`
- ‚úÖ `frequency_tables_regions.csv`

#### En `outputs/results/models/`:
- ‚úÖ `linear_regression_simple.pkl`
- ‚úÖ `linear_regression_multiple.pkl`
- ‚úÖ `kmeans_model.pkl`
- ‚úÖ `kmeans_scaler.pkl`
- ‚úÖ `pca_model.pkl`

---

## üêõ Soluci√≥n de Problemas

### Problema 1: "No se encontr√≥ el archivo"

**Error:**
```
‚ùå ERROR: No se encontr√≥ el archivo data/raw/Earthquakes_USGS.csv
```

**Soluci√≥n:**
1. Verifica que el archivo est√© en la ubicaci√≥n correcta
2. Verifica que el nombre sea exactamente `Earthquakes_USGS.csv`
3. Aseg√∫rate de estar en el directorio correcto del proyecto

---

### Problema 2: "ModuleNotFoundError"

**Error:**
```
ModuleNotFoundError: No module named 'pandas'
```

**Soluci√≥n:**
```powershell
pip install pandas numpy matplotlib seaborn scikit-learn scipy
```

Si persiste, verifica tu instalaci√≥n de Python:
```powershell
python --version
pip --version
```

---

### Problema 3: Errores en R

**Error:**
```
Error: package 'ggplot2' not found
```

**Soluci√≥n:**
```r
install.packages("ggplot2")
```

---

### Problema 4: Memoria insuficiente

Si el dataset es muy grande (>500MB):

**Soluci√≥n en Python:**
Edita los scripts y activa el muestreo:
```python
# En la funci√≥n load_data, cambia:
SAMPLE_SIZE = 100000  # Usar solo 100,000 registros
```

**Soluci√≥n en R:**
```r
# En 02_maps_visualization.R, ajusta:
SAMPLE_SIZE <- 30000
```

---

## üí° Tips y Mejores Pr√°cticas

### Para el Informe:

1. **Usa las "Frases Sugeridas"** que aparecen en los reportes de texto
2. **Incluye las visualizaciones** generadas en `outputs/figures/`
3. **Cita las m√©tricas** de los modelos (R¬≤, Silhouette Score, etc.)
4. **Interpreta los resultados** con las notas incluidas en los scripts

### Para la Presentaci√≥n:

1. **Selecciona 4-6 gr√°ficos clave:**
   - Distribuci√≥n de magnitudes
   - Tendencia temporal
   - Mapa de alta magnitud
   - Resultados de clustering

2. **Estructura sugerida:**
   - Slide 1: Introducci√≥n y objetivos
   - Slide 2: Dataset y metodolog√≠a
   - Slide 3-4: An√°lisis descriptivo con gr√°ficos
   - Slide 5-6: Modelos y resultados
   - Slide 7: Conclusiones y recomendaciones

### Para Experimentar M√°s:

1. **Cambia par√°metros de clustering:**
   ```python
   # En 04_analytical_models.py
   clustering = kmeans_clustering(df, n_clusters=7)  # Probar con 7 clusters
   ```

2. **Filtra por regiones espec√≠ficas:**
   ```python
   df_california = df[df['place'].str.contains('California', na=False)]
   ```

3. **Analiza per√≠odos espec√≠ficos:**
   ```python
   df_recent = df[df['year'] >= 2000]
   ```

---

## üìö Recursos Adicionales

### Documentaci√≥n Oficial:
- **Pandas:** https://pandas.pydata.org/docs/
- **Scikit-learn:** https://scikit-learn.org/stable/
- **ggplot2:** https://ggplot2.tidyverse.org/
- **USGS:** https://earthquake.usgs.gov/

### Tutoriales Recomendados:
- Python para Data Science: https://www.kaggle.com/learn/python
- R para visualizaciones: https://r4ds.had.co.nz/
- Machine Learning b√°sico: https://www.coursera.org/learn/machine-learning

---

## üìû Soporte

Si encuentras problemas:

1. **Revisa los mensajes de error** - suelen indicar qu√© falta
2. **Verifica las rutas de archivos** - deben ser absolutas o relativas correctas
3. **Comprueba las versiones** de Python y paquetes
4. **Consulta los comentarios** en el c√≥digo - hay explicaciones detalladas

---

## ‚úÖ Checklist Final

Antes de entregar tu proyecto, verifica:

- [ ] Todos los scripts ejecutan sin errores
- [ ] Se generaron todas las figuras (16 archivos .png)
- [ ] Los reportes de texto est√°n completos
- [ ] El dataset limpio fue creado
- [ ] Los modelos fueron guardados
- [ ] Las visualizaciones son legibles y profesionales
- [ ] El informe incluye citas de los resultados
- [ ] La presentaci√≥n tiene 7-10 slides m√°ximo
- [ ] Has interpretado los resultados (no solo copiar n√∫meros)

---

**¬°√âxito con tu proyecto!** üéâ

*Desarrollado con ‚ù§Ô∏è para Miner√≠a de Datos 2025*
